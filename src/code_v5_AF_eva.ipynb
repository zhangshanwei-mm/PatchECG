{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import sys\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, \\\n",
    "    roc_auc_score, f1_score,auc,roc_curve,multilabel_confusion_matrix\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from helper_code import *\n",
    "from utils import *\n",
    "from new_utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchsummary import summary\n",
    "import pickle\n",
    "import math\n",
    "from my_transformer import *\n",
    "import seaborn as sns\n",
    "import ast,h5py\n",
    "import json\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "np.random.seed(40) # 45\n",
    "device_str = \"cuda:9\"\n",
    "\n",
    "\n",
    "def load_raw_data(df, sampling_rate, path):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "# Extract features.\n",
    "def extract_features(record): # extract feature\n",
    "    # 空数据全部置为0，即可\n",
    "    lead_12,fields = load_signals(record)\n",
    "    a = np.array(lead_12)\n",
    "    b = np.transpose(a,[1,0]) # change dim\n",
    "    df = pd.DataFrame(b) \n",
    "    arr = df.fillna(0).values\n",
    "    signal = list(arr)\n",
    "    return signal\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data,label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        # self.patch_length = patch_length\n",
    "        # self.stride = stride\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # slide sequence to patch\n",
    "        raw_data = np.array(self.data[index]) # (12,1000)\n",
    "        # (12,1000) -> (12,num_patch,patch_length)  切割数据集\n",
    "        total_length = raw_data.shape[1] # 1000\n",
    "        patch_length = 64\n",
    "        stride = 16\n",
    "        \n",
    "        # # ==================================================================================================================================\n",
    "        # # 判断是否需要填充数据\n",
    "        # # remainder = (total_length- patch_length) % stride\n",
    "        # # if remainder !=0:\n",
    "        # #     padding_needed = stride-remainder # 需要填充的数量\n",
    "        # #     print(padding_needed)\n",
    "        # #     padded_data = np.pad(raw_data, ((0, 0), (0, padding_needed)), mode='constant', constant_values=0)\n",
    "        # #     print(padded_data.shape) # \n",
    "        \n",
    "        \n",
    "        # # 处理最后一个确实的部分\n",
    "        # channel_num_patch = (total_length-patch_length)//stride+1 # 59 update->60\n",
    "        \n",
    "        # # print(channel_num_patch)\n",
    "        # # 创建一个空数组来存储划分后的数据\n",
    "        # sliced_data = np.empty((12, channel_num_patch, patch_length)) # shape (12,59,64)\n",
    "        \n",
    "        # for i in range(channel_num_patch): # 59\n",
    "        #     start = i * stride\n",
    "        #     end = start + patch_length\n",
    "        #     # sliced_data[:, i, :] = raw_data[:, start:end] # 最后一个直接神略\n",
    "        #     sliced_data[:, i, :] = raw_data[:, start:end] # 添加最后一个，用0进行填充 （12,60,64）\n",
    "        \n",
    "        \n",
    "        # # print(sliced_data.shape) # 12,59,64 -> 12,60,64\n",
    "        # # ==================================================================================================================================\n",
    "        \n",
    "        # 第二种patch的方案\n",
    "        # sliced_data = silde_windows_without_overlap(raw_data,patch_length) # （12,16,64）\n",
    "        \n",
    "        # 不要最后一个不完整的，不重叠\n",
    "        sliced_data = silde_windows_without_overlap_v1(raw_data,patch_length)# （12,15,64）\n",
    "        \n",
    "        # print(sliced_data.shape) \n",
    "        \n",
    "        return (torch.tensor(sliced_data, dtype=torch.float), torch.tensor(self.label[index], dtype=torch.float))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "      \n",
    "class MyConv1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.Conv1d to support SAME padding\n",
    "\n",
    "    input: (n_sample, in_channels, n_length)\n",
    "    output: (n_sample, out_channels, (n_length+stride-1)//stride)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1):\n",
    "        super(MyConv1dPadSame, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channels=self.in_channels, \n",
    "            out_channels=self.out_channels, \n",
    "            kernel_size=self.kernel_size, \n",
    "            stride=self.stride, \n",
    "            groups=self.groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        net = x\n",
    "        \n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "        \n",
    "        net = self.conv(net)\n",
    "\n",
    "        return net\n",
    "        \n",
    "class MyMaxPool1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.MaxPool1d to support SAME padding\n",
    "\n",
    "    params:\n",
    "        kernel_size: kernel size\n",
    "        stride: the stride of the window. Default value is kernel_size\n",
    "    \n",
    "    input: (n_sample, n_channel, n_length)\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(MyMaxPool1dPadSame, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.max_pool = torch.nn.MaxPool1d(kernel_size=self.kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        net = x\n",
    "        \n",
    "        # compute pad shape\n",
    "        p = max(0, self.kernel_size - 1)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "        \n",
    "        net = self.max_pool(net)\n",
    "        \n",
    "        return net\n",
    "    \n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x): # a activation function\n",
    "        return x * F.sigmoid(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic Block: \n",
    "        conv1 -> convk -> conv1\n",
    "\n",
    "    params:\n",
    "        in_channels: number of input channels\n",
    "        out_channels: number of output channels\n",
    "        ratio: ratio of channels to out_channels\n",
    "        kernel_size: kernel window length\n",
    "        stride: kernel step size\n",
    "        groups: number of groups in convk\n",
    "        downsample: whether downsample length\n",
    "        use_bn: whether use batch_norm\n",
    "        use_do: whether use dropout\n",
    "\n",
    "    input: (n_sample, in_channels, n_length)\n",
    "    output: (n_sample, out_channels, (n_length+stride-1)//stride)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, ratio, kernel_size, stride, groups, downsample, is_first_block=False, use_bn=True, use_do=True):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.ratio = ratio\n",
    "        self.kernel_size = kernel_size\n",
    "        self.groups = groups\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride if self.downsample else 1\n",
    "        self.is_first_block = is_first_block\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        self.middle_channels = int(self.out_channels * self.ratio)\n",
    "\n",
    "        # the first conv, conv1\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.activation1 = Swish()\n",
    "        self.do1 = nn.Dropout(p=0.5)\n",
    "        self.conv1 = MyConv1dPadSame(\n",
    "            in_channels=self.in_channels, \n",
    "            out_channels=self.middle_channels, \n",
    "            kernel_size=1, \n",
    "            stride=1,\n",
    "            groups=1)\n",
    "\n",
    "        # the second conv, convk\n",
    "        self.bn2 = nn.BatchNorm1d(self.middle_channels)\n",
    "        self.activation2 = Swish()\n",
    "        self.do2 = nn.Dropout(p=0.5)\n",
    "        self.conv2 = MyConv1dPadSame(\n",
    "            in_channels=self.middle_channels, \n",
    "            out_channels=self.middle_channels, \n",
    "            kernel_size=self.kernel_size, \n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "        # the third conv, conv1\n",
    "        self.bn3 = nn.BatchNorm1d(self.middle_channels)\n",
    "        self.activation3 = Swish()\n",
    "        self.do3 = nn.Dropout(p=0.5)\n",
    "        self.conv3 = MyConv1dPadSame(\n",
    "            in_channels=self.middle_channels, \n",
    "            out_channels=self.out_channels, \n",
    "            kernel_size=1, \n",
    "            stride=1,\n",
    "            groups=1)\n",
    "\n",
    "        # Squeeze-and-Excitation\n",
    "        r = 2\n",
    "        self.se_fc1 = nn.Linear(self.out_channels, self.out_channels//r)\n",
    "        self.se_fc2 = nn.Linear(self.out_channels//r, self.out_channels)\n",
    "        self.se_activation = Swish()\n",
    "\n",
    "        if self.downsample:\n",
    "            self.max_pool = MyMaxPool1dPadSame(kernel_size=self.stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        identity = x\n",
    "        \n",
    "        out = x\n",
    "        # the first conv, conv1\n",
    "        if not self.is_first_block:\n",
    "            if self.use_bn:\n",
    "                out = self.bn1(out)\n",
    "            out = self.activation1(out)\n",
    "            if self.use_do:\n",
    "                out = self.do1(out)\n",
    "        out = self.conv1(out)\n",
    "        \n",
    "        # the second conv, convk\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "        out = self.activation2(out)\n",
    "        if self.use_do:\n",
    "            out = self.do2(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        # the third conv, conv1\n",
    "        if self.use_bn:\n",
    "            out = self.bn3(out)\n",
    "        out = self.activation3(out)\n",
    "        if self.use_do:\n",
    "            out = self.do3(out)\n",
    "        out = self.conv3(out) # (n_sample, n_channel, n_length)\n",
    "\n",
    "        # Squeeze-and-Excitation\n",
    "        se = out.mean(-1) # (n_sample, n_channel) ,求均值\n",
    "        se = self.se_fc1(se)\n",
    "        se = self.se_activation(se)\n",
    "        se = self.se_fc2(se)\n",
    "        se = F.sigmoid(se) # (n_sample, n_channel)\n",
    "        out = torch.einsum('abc,ab->abc', out, se)\n",
    "        \n",
    "        # if downsample, also downsample identity\n",
    "        if self.downsample:\n",
    "            identity = self.max_pool(identity)\n",
    "            \n",
    "        # if expand channel, also pad zeros to identity\n",
    "        if self.out_channels != self.in_channels:\n",
    "            identity = identity.transpose(-1,-2)\n",
    "            ch1 = (self.out_channels-self.in_channels)//2\n",
    "            ch2 = self.out_channels-self.in_channels-ch1\n",
    "            identity = F.pad(identity, (ch1, ch2), \"constant\", 0)\n",
    "            identity = identity.transpose(-1,-2)\n",
    "        \n",
    "        # shortcut\n",
    "        out += identity\n",
    "\n",
    "        return out\n",
    "\n",
    "class BasicStage(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic Stage:\n",
    "        block_1 -> block_2 -> ... -> block_M\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, ratio, kernel_size, stride, groups, i_stage, m_blocks, use_bn=True, use_do=True, verbose=False):\n",
    "        super(BasicStage, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.ratio = ratio\n",
    "        self.kernel_size = kernel_size\n",
    "        self.groups = groups\n",
    "        self.i_stage = i_stage\n",
    "        self.m_blocks = m_blocks\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.block_list = nn.ModuleList()\n",
    "        for i_block in range(self.m_blocks):\n",
    "            \n",
    "            # first block\n",
    "            if self.i_stage == 0 and i_block == 0:\n",
    "                self.is_first_block = True\n",
    "            else:\n",
    "                self.is_first_block = False\n",
    "            # downsample, stride, input\n",
    "            if i_block == 0:\n",
    "                self.downsample = True\n",
    "                self.stride = stride\n",
    "                self.tmp_in_channels = self.in_channels\n",
    "            else:\n",
    "                self.downsample = False\n",
    "                self.stride = 1\n",
    "                self.tmp_in_channels = self.out_channels\n",
    "            \n",
    "            # build block\n",
    "            tmp_block = BasicBlock(\n",
    "                in_channels=self.tmp_in_channels, \n",
    "                out_channels=self.out_channels, \n",
    "                ratio=self.ratio, \n",
    "                kernel_size=self.kernel_size, \n",
    "                stride=self.stride, \n",
    "                groups=self.groups, \n",
    "                downsample=self.downsample, \n",
    "                is_first_block=self.is_first_block,\n",
    "                use_bn=self.use_bn, \n",
    "                use_do=self.use_do)\n",
    "            self.block_list.append(tmp_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = x\n",
    "\n",
    "        for i_block in range(self.m_blocks):\n",
    "            net = self.block_list[i_block]\n",
    "            out = net(out)\n",
    "            if self.verbose:\n",
    "                print('stage: {}, block: {}, in_channels: {}, out_channels: {}, outshape: {}'.format(self.i_stage, i_block, net.in_channels, net.out_channels, list(out.shape)))\n",
    "                print('stage: {}, block: {}, conv1: {}->{} k={} s={} C={}'.format(self.i_stage, i_block, net.conv1.in_channels, net.conv1.out_channels, net.conv1.kernel_size, net.conv1.stride, net.conv1.groups))\n",
    "                print('stage: {}, block: {}, convk: {}->{} k={} s={} C={}'.format(self.i_stage, i_block, net.conv2.in_channels, net.conv2.out_channels, net.conv2.kernel_size, net.conv2.stride, net.conv2.groups))\n",
    "                print('stage: {}, block: {}, conv1: {}->{} k={} s={} C={}'.format(self.i_stage, i_block, net.conv3.in_channels, net.conv3.out_channels, net.conv3.kernel_size, net.conv3.stride, net.conv3.groups))\n",
    "\n",
    "        return out\n",
    "\n",
    "class Net1D(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    Input:\n",
    "        X: (n_samples, n_channel, n_length)\n",
    "        Y: (n_samples)\n",
    "        \n",
    "    Output:\n",
    "        out: (n_samples)\n",
    "        \n",
    "    params:\n",
    "        in_channels\n",
    "        base_filters\n",
    "        filter_list: list, filters for each stage\n",
    "        m_blocks_list: list, number of blocks of each stage\n",
    "        kernel_size\n",
    "        stride\n",
    "        groups_width\n",
    "        n_stages\n",
    "        n_classes\n",
    "        use_bn\n",
    "        use_do\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, base_filters, ratio, filter_list, m_blocks_list, kernel_size, stride, groups_width, n_classes, use_bn=True, use_do=True, verbose=False):\n",
    "        super(Net1D, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.base_filters = base_filters\n",
    "        self.ratio = ratio\n",
    "        self.filter_list = filter_list\n",
    "        self.m_blocks_list = m_blocks_list\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups_width = groups_width\n",
    "        self.n_stages = len(filter_list)\n",
    "        self.n_classes = n_classes\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # first conv\n",
    "        self.first_conv = MyConv1dPadSame(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=self.base_filters, \n",
    "            kernel_size=self.kernel_size, \n",
    "            stride=2)\n",
    "        self.first_bn = nn.BatchNorm1d(base_filters)\n",
    "        self.first_activation = Swish()\n",
    "\n",
    "        # stages\n",
    "        self.stage_list = nn.ModuleList()\n",
    "        in_channels = self.base_filters\n",
    "        for i_stage in range(self.n_stages):\n",
    "\n",
    "            out_channels = self.filter_list[i_stage]\n",
    "            m_blocks = self.m_blocks_list[i_stage]\n",
    "            tmp_stage = BasicStage(\n",
    "                in_channels=in_channels, \n",
    "                out_channels=out_channels, \n",
    "                ratio=self.ratio, \n",
    "                kernel_size=self.kernel_size, \n",
    "                stride=self.stride, \n",
    "                groups=out_channels//self.groups_width, \n",
    "                i_stage=i_stage,\n",
    "                m_blocks=m_blocks, \n",
    "                use_bn=self.use_bn, \n",
    "                use_do=self.use_do, \n",
    "                verbose=self.verbose)\n",
    "            self.stage_list.append(tmp_stage)\n",
    "            in_channels = out_channels\n",
    "\n",
    "        # final prediction\n",
    "        self.dense = nn.Linear(in_channels, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x [1,1,64]\n",
    "        out = x\n",
    "        # first conv\n",
    "        out = self.first_conv(out)\n",
    "        if self.use_bn:\n",
    "            out = self.first_bn(out)\n",
    "        out = self.first_activation(out)\n",
    "        \n",
    "        # stages\n",
    "        for i_stage in range(self.n_stages):\n",
    "            net = self.stage_list[i_stage]\n",
    "            out = net(out)\n",
    "\n",
    "        # final prediction\n",
    "        out = out.mean(-1)\n",
    "        out = self.dense(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "def my_mask(lead_tp = 1, len = 1000):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        lead_tp : type of ECG , 1 表示12，1的排布，2表示3，4的排布，3表示6，2的排布\n",
    "        len : 数据的长度\n",
    "    retrun (12,length)\n",
    "    \"\"\"\n",
    "    step = 1000\n",
    "    if lead_tp == 2: \n",
    "        step = int(len/4)\n",
    "    if lead_tp == 3:\n",
    "        step = int(len/2)\n",
    "        \n",
    "    #print(\"每条导联的长度：\"+str(step))\n",
    "    msk = np.zeros((12,len))\n",
    "    \n",
    "    if lead_tp == 2:\n",
    "        msk[0,step:len] = 1\n",
    "        msk[2,step:len] = 1\n",
    "        \n",
    "        msk[3,0:step] = 1\n",
    "        msk[3,2*step:len] = 1\n",
    "        msk[4,0:step] = 1\n",
    "        msk[4,2*step:len] = 1\n",
    "        msk[5,0:step] = 1\n",
    "        msk[5,2*step:len] = 1\n",
    "        \n",
    "        msk[6,0:2*step] = 1\n",
    "        msk[6,3*step:len] = 1\n",
    "        msk[7,0:2*step] = 1\n",
    "        msk[7,3*step:len] = 1\n",
    "        msk[8,0:2*step] = 1\n",
    "        msk[8,3*step:len] = 1\n",
    "        \n",
    "        msk[9,0:3*step] = 1\n",
    "        msk[10,0:3*step] = 1\n",
    "        msk[11,0:3*step] = 1\n",
    "        \n",
    "    if lead_tp == 3:\n",
    "        msk[0,step:len] = 1\n",
    "        msk[2,step:len] = 1\n",
    "        msk[3,step:len] = 1\n",
    "        msk[4,step:len] = 1\n",
    "        msk[5,step:len] = 1\n",
    "\n",
    "        msk[6,0:step] = 1\n",
    "        msk[7,0:step] = 1\n",
    "        msk[8,0:step] = 1\n",
    "        msk[9,0:step] = 1\n",
    "        msk[10,0:step] = 1\n",
    "        msk[11,0:step] = 1\n",
    "         \n",
    "    return msk\n",
    "\n",
    "def encode_labels(data, label_to_index):\n",
    "# 初始化零矩阵，形状为[数据长度, 标签数量]\n",
    "    target = torch.zeros((len(data), len(label_to_index)), dtype=torch.float32)\n",
    "    \n",
    "    # 填充矩阵\n",
    "    for i, items in enumerate(data):\n",
    "        for item in items:\n",
    "            if item in label_to_index:\n",
    "                target[i, label_to_index[item]] = 1\n",
    "    \n",
    "    return target\n",
    "\n",
    "\n",
    "# transformer model\n",
    "class TransformerEncoderForMultiLabelClassification(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward, num_labels, dropout=0.1):\n",
    "        super(TransformerEncoderForMultiLabelClassification, self).__init__()\n",
    "        \"\"\"\n",
    "            d_model:输入vector的维度\n",
    "            nhead \n",
    "            num_layers:\n",
    "            dim_feedforward : 前馈神经网络的隐藏测层维度\n",
    "            dropout : \n",
    "            输出：\n",
    "        \"\"\"\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.num_layers = num_layers\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        # 位置编码\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, 1000, d_model))\n",
    "        \n",
    "        # self.time_positional_encoding = positionalencoding1d(708,d_model).unsqueeze(0) # (1,length,d_model) 708,128\n",
    "        self.time_positional_encoding = positionalencoding1d(180,d_model).unsqueeze(0)\n",
    "        # Transformer编码器层\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # 全连接层用于多标签分类\n",
    "        # self.fc1 = nn.Linear(d_model*708, 128) # 90624 的输入\n",
    "        self.fc1 = nn.Linear(d_model*180, 128)\n",
    "        self.fc2 = nn.Linear(128, num_labels)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # input (batch,length,d_model) 16,708,128\n",
    "        # src: (batch, length, d_model)\n",
    "        batch_size, length, d_model = src.size()\n",
    "        \n",
    "        # 添加位置编码\n",
    "        # pe = self.positional_encoding[:length,d_model] # shape (d_model,length) 708,128 ->1,708,128\n",
    "        # pe.to(\"cuda:2\")\n",
    "        # time_position = pe.unsqueeze(0) # 708,128 ->1,708,128\n",
    "        # src = src + self.positional_encoding[:, :length, :] \n",
    "        self.time_positional_encoding.to(\"cuda:3\")\n",
    "        # print(self.time_positional_encoding.shape) # (1,length,d_model) 1,708,128\n",
    "        \n",
    "        src = src + self.time_positional_encoding\n",
    "        \n",
    "        # 调整维度顺序以适应Transformer的输入要求 (length, batch, d_model)\n",
    "        # src = src.permute(1, 0, 2)\n",
    "        # print(\"print input transformer dim:..\")\n",
    "        # print(src.shape) # 16,708,128\n",
    "        \n",
    "        # 通过Transformer编码器\n",
    "        output = self.transformer_encoder(src)\n",
    "        # print(output.shape) # 16,708,128\n",
    "        output = torch.flatten(output,1) # (16,708,128) - > (16,90624)\n",
    "        \n",
    "        # print(output.shape) # （16,90624）\n",
    "                \n",
    "        output = self.fc1(output)\n",
    "        output = self.fc2(output)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        # # 调整回原来的维度顺序 (batch, length, d_model)\n",
    "        # output = output.permute(1, 0, 2)\n",
    "        # 取最后一个时间步的输出作为分类器的输入\n",
    "        # cls_output = output[:, -1, :]  # (batch, d_model)\n",
    "        # 通过全连接层进行多标签分类\n",
    "        # logits = self.fc(cls_output)  # (batch, num_labels)\n",
    "        return output\n",
    "\n",
    "\n",
    "def positionalencoding1d(length, d_model):\n",
    "    \"\"\"\n",
    "        input : param d_model: dimension of the model\n",
    "              : param length: length of positions\n",
    "        output : return: length*d_model position matrix\n",
    "        \n",
    "    \"\"\"\n",
    "    if d_model % 2 != 0:\n",
    "        raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
    "                         \"odd dim (got dim={:d})\".format(d_model))\n",
    "    pe = torch.zeros(length, d_model).to(\"cuda:3\")\n",
    "    position = torch.arange(0, length).unsqueeze(1).to(\"cuda:3\")\n",
    "    div_term = torch.exp((torch.arange(0, d_model, 2, dtype=torch.float) *\n",
    "                         -(math.log(10000.0) / d_model))).to(\"cuda:3\")\n",
    "    pe[:, 0::2] = torch.sin(position.float() * div_term).to(\"cuda:3\")\n",
    "    pe[:, 1::2] = torch.cos(position.float() * div_term).to(\"cuda:3\")\n",
    "\n",
    "    \n",
    "    return pe \n",
    "        \n",
    "def positionalencoding2d(d_model, height, width):\n",
    "    \"\"\"\n",
    "    :param d_model: dimension of the model\n",
    "    :param height: height of the positions\n",
    "    :param width: width of the positions\n",
    "    :return: d_model*height*width position matrix\n",
    "    \"\"\"\n",
    "    if d_model % 4 != 0:\n",
    "        raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
    "                         \"odd dimension (got dim={:d})\".format(d_model))\n",
    "    pe = torch.zeros(d_model, height, width)\n",
    "    # Each dimension use half of d_model\n",
    "    d_model = int(d_model / 2)\n",
    "    div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                         -(math.log(10000.0) / d_model))\n",
    "    pos_w = torch.arange(0., width).unsqueeze(1)\n",
    "    pos_h = torch.arange(0., height).unsqueeze(1)\n",
    "    pe[0:d_model:2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
    "    pe[1:d_model:2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
    "    pe[d_model::2, :, :] = torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
    "    pe[d_model + 1::2, :, :] = torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
    "\n",
    "    return pe\n",
    "\n",
    "def create_2d_relative_bias_trainble_embeddings(n_head,height,width,dim):\n",
    "    position_embedding = nn.Embedding((2*width-1)*(2*height-1),n_head)\n",
    "    nn.init.constant_(position_embedding,0.)\n",
    "    def get_relative_position_index(height,width):\n",
    "        coords = torch.stack(torch.meshgrid(torch.arange(height),torch.arange(width))) # [2,height,width]\n",
    "        coords_flatten = torch.flatten(coords,1) # [2,height * width]\n",
    "        relative_coords_bias = coords_flatten[:,:,None]-coords_flatten[:,None,:] # [2,height*width,height*width]\n",
    "        \n",
    "        relative_coords_bias[0,:,:] += height - 1\n",
    "        relative_coords_bias[1,:,:] += width - 1\n",
    "        \n",
    "        relative_coords_bias[0,:,:] *= relative_coords_bias[1,:,:].max()+1\n",
    "        return relative_coords_bias.sum(0) # [height * width,height * width]\n",
    "    \n",
    "    relative_position_bias = get_relative_position_index(height,width)\n",
    "    bias_embedding = position_embedding(torch.flatten(relative_position_bias)).reshape(height*width,height*width,n_head) # [height*width,height*width,n_head]\n",
    "    bias_embedding = bias_embedding.permute(2,0,1).unsqueeze(0) # [1,n_head,height*width,height*width]\n",
    "    \n",
    "    return bias_embedding\n",
    "\n",
    "def create_2d_absolate_sincos_embeddings(height,width,dim):\n",
    "    \"\"\"\n",
    "        2d 绝对路径的embedding\n",
    "    \"\"\"\n",
    "    assert dim % 4==0,\"wrong dimension\"\n",
    "    \n",
    "    position_embedding = torch.zeros(height*width,dim)\n",
    "    coords = torch.stack()\n",
    "    return position_embedding\n",
    "\n",
    "def silde_windows(data,stride,patch_length):\n",
    "    \"\"\"\n",
    "        input :\n",
    "            data : (channel,length)\n",
    "            stride :\n",
    "            patch_length : \n",
    "        output : (channel,num_patch,patch_length)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    total_length = data.shape[1]\n",
    "    channel = data.shap[0]\n",
    "    \n",
    "    # 判断是否需要填充数据\n",
    "    \n",
    "    \n",
    "    return 1\n",
    "\n",
    "def silde_windows_without_overlap(data,patch_length):\n",
    "    \"\"\"\n",
    "        input :\n",
    "            data : (channel,length)\n",
    "            stride :\n",
    "            patch_length : \n",
    "        output : (channel,num_patch,patch_length) ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    total_length = data.shape[1] # 1000\n",
    "    channel = data.shape[0] # 12\n",
    "    \n",
    "    # 判断需要填充的数据\n",
    "    remainder = total_length % patch_length # 40\n",
    "    padding_needed = 0 if remainder == 0 else patch_length - remainder  # 24\n",
    "    padded_data = np.pad(data, ((0, 0), (0, padding_needed)), mode='constant', constant_values=0) # (12,1024)\n",
    "    num_patch = int(padded_data.shape[1]/patch_length) # 16\n",
    "    sliced_data = np.empty((channel, num_patch, patch_length)) # 12,16,64\n",
    "    for i in range(num_patch): # 16\n",
    "        start = i * patch_length\n",
    "        end = start + patch_length\n",
    "        # sliced_data[:, i, :] = raw_data[:, start:end] # 最后一个直接神略\n",
    "        sliced_data[:, i, :] = padded_data[:, start:end] # 添加最后一个，用0进行填充 \n",
    "    \n",
    "    return sliced_data\n",
    "\n",
    "def silde_windows_without_overlap_v1(data,patch_length):\n",
    "    \"\"\"\n",
    "        input:\n",
    "            data : (channel,length)\n",
    "            stride :\n",
    "            patch_length : \n",
    "        output : (channel,num_patch,patch_length) ndarray\n",
    "        comment : 不要最后一个缺失的块\n",
    "    \"\"\"\n",
    "    total_length = data.shape[1] # 1000\n",
    "    channel = data.shape[0] # 12\n",
    "    stride = patch_length\n",
    "    # 不要最后一个\n",
    "    num_patch = (total_length-patch_length)//stride+1 \n",
    "    sliced_data = np.empty((channel, num_patch, patch_length))\n",
    "    for i in range(num_patch): # 16\n",
    "        start = i * patch_length\n",
    "        end = start + patch_length\n",
    "        # sliced_data[:, i, :] = raw_data[:, start:end] # 最后一个直接神略\n",
    "        sliced_data[:, i, :] = data[:, start:end] # 添加最后一个，用0进行填充 \n",
    "    \n",
    "    return sliced_data\n",
    "\n",
    "# 计算评估指标\n",
    "\n",
    "def evaluate_binary_classification(y_true, y_prob, threshold=0.5):\n",
    "    \"\"\"\n",
    "    评估二分类任务，输入真实标签和预测概率\n",
    "\n",
    "    参数：\n",
    "        y_true: ndarray, shape (n,) or (n,1)，真实标签，0/1\n",
    "        y_prob: ndarray, shape (n,) or (n,1)，预测概率（sigmoid 输出）\n",
    "        threshold: float，用于将概率转换为0/1预测标签\n",
    "\n",
    "    返回：\n",
    "        指标字典\n",
    "    \"\"\"\n",
    "    # 展平\n",
    "    y_true = y_true.reshape(-1)\n",
    "    y_prob = y_prob.reshape(-1)\n",
    "\n",
    "    # 概率 → 二值预测\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # 基本指标\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    # 混淆矩阵\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1 Score': f1,\n",
    "        'Specificity': specificity,\n",
    "        'AUC-ROC': auc,\n",
    "        'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF chaoyang data shape : (400, 12, 1000)\n",
      "AF chaoyang label shape :(400, 1)\n",
      "Building S3 Layer 0\n",
      "Building S3 Layer 1\n",
      "Building S3 Layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC 400 = 0.7776\n",
      "推荐阈值 = 0.22\n",
      "推荐阈值 = 0.22\n",
      "TP is 150\n",
      "FP is 52\n",
      "FN is 50\n",
      "TN is 148\n",
      "accuracy: 0.7450\n",
      "precision: 0.7426\n",
      "recall: 0.7500\n",
      "specificity: 0.7400\n",
      "f1_score: 0.7463\n",
      "==============================\n",
      "AUROC 300 12 x 1 = 0.8931\n",
      "TP is 81\n",
      "FP is 31\n",
      "FN is 19\n",
      "TN is 169\n",
      "accuracy: 0.8333\n",
      "precision: 0.7232\n",
      "recall: 0.8100\n",
      "specificity: 0.8450\n",
      "f1_score: 0.7642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "with h5py.File('/data/0shared/zhangshanwei/cinc/ours/data/chaoyan_AF_6x2.h5', 'r') as f:\n",
    "    data1 = f['data'][:]\n",
    "    numbers1 = f['numbers'][:]\n",
    "    \n",
    "# read 12x1 AF 100 张\n",
    "with h5py.File('/data/0shared/zhangshanwei/cinc/ours/data/chaoyan_AF_12x1.h5', 'r') as f:\n",
    "    data2 = f['data'][:]\n",
    "    numbers2 = f['numbers'][:]\n",
    "\n",
    "# read NAF 200 张\n",
    "with h5py.File('/data/0shared/zhangshanwei/cinc/ours/data/chaoyan_NAF.h5', 'r') as f:\n",
    "    data3 = f['data'][:]\n",
    "    numbers3 = f['numbers'][:]\n",
    "\n",
    "data1 = np.moveaxis(data1, 1, 2)\n",
    "data2 = np.moveaxis(data2, 1, 2)\n",
    "data3 = np.moveaxis(data3, 1, 2)\n",
    "\n",
    "af_test_data = np.concatenate((data1, data2, data3), axis=0) # [400,1000,12]\n",
    "af_test_label = np.concatenate([np.ones((200, 1)), np.zeros((200, 1))])\n",
    "\n",
    "print(f\"AF chaoyang data shape : {af_test_data.shape}\")\n",
    "print(f\"AF chaoyang label shape :{af_test_label.shape}\")\n",
    "\n",
    "n_epoch = 30\n",
    "batch_size = 1\n",
    "input_dim = 768\n",
    "header = 16\n",
    "num_layers = 4\n",
    "s = 16 # stride\n",
    "patch_len = 64\n",
    "\n",
    "\n",
    "dataset_test_AF = MyDataset(af_test_data,af_test_label)\n",
    "dataloader_test_AF = DataLoader(dataset_test_AF, batch_size=batch_size, drop_last=True)\n",
    "device = torch.device(device_str if torch.cuda.is_available() else \"cpu\")\n",
    "model1 = Net1D(\n",
    "    in_channels=2, \n",
    "    base_filters=16, \n",
    "    ratio=1.0, \n",
    "    filter_list=[16,32,32,40,40,64,64], # [16,32,32,40,40,64,64]\n",
    "    m_blocks_list=[2,2,2,2,2,2,2], # [2,2,2,2,2,2,2]\n",
    "    kernel_size=16, \n",
    "    stride=2, \n",
    "    groups_width=16,\n",
    "    verbose=False,\n",
    "    n_classes=768)\n",
    "parameters = torch.load('/data/0shared/zhangshanwei/cinc/ours/src/AF/model/checkpoint_29.pth', map_location='cuda:9')\n",
    "\n",
    "model1.load_state_dict(parameters['model1'])\n",
    "model1.to(device)\n",
    "\n",
    "model3 = VisionTransformer_2dembedding_v2(\n",
    "                            embed_dim=768,\n",
    "                            depth=3,\n",
    "                            num_heads=8,\n",
    "                            representation_size=None,\n",
    "                            num_classes=1,\n",
    "                            num_patch = 15,\n",
    "                            channel = 12,\n",
    "                            drop_ratio=0.,\n",
    "                            attn_drop_ratio=0., \n",
    "                            drop_path_ratio=0.\n",
    "                            )\n",
    "model3.load_state_dict(parameters['model2'])\n",
    "model3.to(device)\n",
    "model_params = list(model1.parameters()) + list(model3.parameters())\n",
    "\n",
    "optimizer = optim.Adam(model_params, lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "# MultiLabelFocalLoss()\n",
    "total_train_loss = [] # loss\n",
    "temp = []\n",
    "step = 0\n",
    "count = 0\n",
    "\n",
    "model1.eval()\n",
    "model3.eval()\n",
    "prog_iter_test = tqdm(dataloader_test_AF, desc=\"Testing\", leave=False)\n",
    "all_test_y = [] # true\n",
    "all_test_pred = [] # pred score\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(prog_iter_test):\n",
    "        input_x, input_y = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        all_test_y.append(input_y.cpu().data.numpy()) # 真实标签\n",
    "\n",
    "        mask = torch.isnan(input_x).all(dim=-1) # B,C,N [256,12,15] \n",
    "        input_x[torch.isnan(input_x)] = 0 # 将所有nan 填充为0\n",
    "        temp_x = input_x.view(input_x.shape[0]*input_x.shape[1]*input_x.shape[2],input_x.shape[3]) # 256 x 12 x15 \n",
    "            \n",
    "        # add 2 channel mask\n",
    "        channel_2_mask = torch.zeros_like(input_x)\n",
    "        channel_2_mask[torch.isnan(input_x)] = 0.0\n",
    "        channel_2_mask[~torch.isnan(input_x)] = 1.0\n",
    "        channel_2_temp = channel_2_mask.reshape(input_x.shape[0]*input_x.shape[1]*input_x.shape[2],input_x.shape[3])\n",
    "        \n",
    "        PatchEncode_output = model1(torch.cat((temp_x.unsqueeze(1), channel_2_temp.unsqueeze(1)), dim=1)) # [256 x 12 x15,1,768]\n",
    "        # [256,12,15,768]\n",
    "        output_x = PatchEncode_output.squeeze(1).view(input_x.shape[0],input_x.shape[1],input_x.shape[2],768)\n",
    "        output_x[mask] = 0\n",
    "\n",
    "        pred = torch.sigmoid(model3(output_x)) # add sigmoid 最后一层需要\n",
    "        all_test_pred.append(pred.cpu().data.numpy()) # add score\n",
    "\n",
    "af_label = np.concatenate(all_test_y)\n",
    "af_score = np.concatenate(all_test_pred)\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def evaluate_predictions(scores, th, labels):\n",
    "    \"\"\"\n",
    "    输入:\n",
    "    scores - 分数数组，形状[400,1]\n",
    "    th - 阈值，大于th的预测为1，否则为0\n",
    "    labels - 真实标签数组，形状[400,1]，前200为1，后200为0\n",
    "    \n",
    "    输出:\n",
    "    predictions - 预测标签数组\n",
    "    confusion_matrix - 混淆矩阵\n",
    "    metrics - 评估指标\n",
    "    \"\"\"\n",
    "    predictions = (scores > th).astype(int)\n",
    "    labels = np.array(labels).reshape(-1, 1)\n",
    "    \n",
    "    TP = np.sum((predictions == 1) & (labels == 1))\n",
    "    FP = np.sum((predictions == 1) & (labels == 0))\n",
    "    FN = np.sum((predictions == 0) & (labels == 1))\n",
    "    TN = np.sum((predictions == 0) & (labels == 0))\n",
    "    \n",
    "    confusion_mat = np.array([[TP, FP], [FN, TN]])\n",
    "    \n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0  # 特异度\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,  # 特异度\n",
    "        'f1_score': f1_score,\n",
    "        'confusion_matrix': confusion_mat\n",
    "    }\n",
    "    print(f\"TP is {TP}\")\n",
    "    print(f\"FP is {FP}\")\n",
    "    print(f\"FN is {FN}\")\n",
    "    print(f\"TN is {TN}\")\n",
    "\n",
    "    for k, v in metrics.items():\n",
    "        if k != 'confusion_matrix':\n",
    "            print(f\"{k}: {v:.4f}\")\n",
    "    \n",
    "\n",
    "Auroc_AF = roc_auc_score(af_label, af_score)\n",
    "print(f\"AUROC 400 = {Auroc_AF:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def find_best_thresholds(labels, scores):\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    optimal_idx = np.argmax(tpr - fpr)  # Youden指数\n",
    "    optimal_thresh = thresholds[optimal_idx]\n",
    "    print(f\"推荐阈值 = {optimal_thresh:.2f}\")\n",
    "\n",
    "    return optimal_thresh\n",
    "best_400_th = find_best_thresholds(af_label, af_score)\n",
    "best_300_th = find_best_thresholds(af_label[100:], af_score[100:])\n",
    "\n",
    "evaluate_predictions(af_score, th=best_400_th, labels=af_label)\n",
    "\n",
    "\n",
    "print(\"==============================\")\n",
    "print(f\"AUROC 300 12 x 1 = {roc_auc_score(af_label[100:], af_score[100:]):.4f}\")\n",
    "evaluate_predictions(af_score[100:], th=best_300_th, labels=af_label[100:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 6, 7, 10, 11, 12, 14]\n",
      "------------------------------\n",
      "[15, 16, 17, 18, 19, 20, 22, 23, 24, 25]\n",
      "------------------------------\n",
      "[26, 29, 33, 34, 35, 36, 37, 39, 40, 41]\n",
      "------------------------------\n",
      "[43, 47, 48, 53, 54, 55, 57, 60, 61, 62]\n",
      "------------------------------\n",
      "[65, 68, 69, 70, 71, 72, 73, 74, 77, 78]\n",
      "------------------------------\n",
      "[79, 81, 82, 83, 85, 86, 87, 91, 93, 95]\n",
      "------------------------------\n",
      "[97, 98, 101, 102, 103, 104, 105, 107, 108, 109]\n",
      "------------------------------\n",
      "[110, 111, 114, 115, 116, 117, 119, 120, 121, 122]\n",
      "------------------------------\n",
      "[123, 124, 128, 129, 130, 131, 132, 133, 134, 135]\n",
      "------------------------------\n",
      "[136, 137, 138, 139, 140, 141, 142, 143, 144, 145]\n",
      "------------------------------\n",
      "[146, 147, 150, 152, 153, 154, 156, 157, 158, 159]\n",
      "------------------------------\n",
      "[160, 161, 162, 163, 164, 165, 166, 167, 168, 170]\n",
      "------------------------------\n",
      "[171, 172, 173, 174, 175, 176, 177, 178, 179, 180]\n",
      "------------------------------\n",
      "[181, 182, 183, 184, 185, 186, 187, 188, 189, 190]\n",
      "------------------------------\n",
      "[191, 192, 193, 194, 195, 196, 197, 198, 199, 200]\n",
      "------------------------------\n",
      "[201, 202, 203, 205, 206, 207, 210, 211, 212, 213]\n",
      "------------------------------\n",
      "[214, 216, 217, 218, 219, 221, 225, 226, 228, 229]\n",
      "------------------------------\n",
      "[230, 231, 232, 233, 234, 235, 238, 239, 241, 242]\n",
      "------------------------------\n",
      "[243, 244, 245, 246, 249, 251, 252, 253, 254, 255]\n",
      "------------------------------\n",
      "[256, 257, 258, 259, 260, 262, 265, 267, 268, 270]\n",
      "------------------------------\n",
      "[271, 273, 274, 275, 276, 277, 278, 279, 280, 281]\n",
      "------------------------------\n",
      "[282, 283, 284, 286, 287, 289, 290, 293, 296, 297]\n",
      "------------------------------\n",
      "[299, 300, 302, 305, 306, 307, 309, 310, 311, 312]\n",
      "------------------------------\n",
      "[315, 317, 318, 319, 321, 322, 323, 324, 325, 326]\n",
      "------------------------------\n",
      "[327, 328, 329, 330, 332, 334, 335, 336, 337, 338]\n",
      "------------------------------\n",
      "[339, 340, 341, 343, 346, 347, 349, 351, 352, 353]\n",
      "------------------------------\n",
      "[354, 355, 356, 357, 359, 361, 362, 363, 364, 366]\n",
      "------------------------------\n",
      "[367, 368, 369, 370, 371, 372, 373, 374, 375, 376]\n",
      "------------------------------\n",
      "[377, 378, 380, 381, 382, 384, 385, 387, 388, 389]\n",
      "------------------------------\n",
      "[390, 394, 395, 396, 397, 398, 399, 400]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 统计一下 正确的index\n",
    "pred_labels = (af_score > best_400_th).astype(int)\n",
    "true_list = []\n",
    "for i in range(400):\n",
    "    if pred_labels[i]==af_label[i]:\n",
    "        true_list.append(i+1)\n",
    "\n",
    "\n",
    "for i in range(0, len(true_list), 10):\n",
    "    chunk = true_list[i:i+10]  # 获取当前10行的切片\n",
    "    print(chunk)\n",
    "    print(\"-\" * 30)  # 分隔线（可选）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cinc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
